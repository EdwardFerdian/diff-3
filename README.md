# DIFF-3
**3D echo** synthetic data generation with **paired labels**. 
This is a PyTorch implementation of the paper submitted to SASHIMI workshop, MICCAI 2023.

## Sample data
Comparison between real and synthetic images+labels generated by DIFF-3

<p align="center">
    <img src="./images/fig_samples.PNG">
</p>

## How To

### Requirements
A conda environment named diff3 can be created and activated with 
  
```
conda env create -f environment.yaml
conda activate diff3
```

Install **diff3** as a package. Go to the directory where the setup.py is located and type
    `pip install -e .`


### 1. VAE Training

#### Prepare training data
Prepare the data by resizing it to 160x160x128. Images are normalized and saved to .npy files by default.
  
    >> python prepare_data.py [-h] --data-dir DATA_DIR --label-dir LABEL_DIR [--image-size IMAGE_SIZE [IMAGE_SIZE ...]] --output-dir OUTPUT_DIR [--subset DATA_SUBSET]
                     [--format FORMAT]

#### Train VAE
Train VAE for 200 epochs with KL_weight adjusted from 1e-6 to 1 after 100 epochs.

Configure the training parameters in the config file, e.g. `./configs/vae_xent.yaml`
        
    >> python autoencoder/trainer_autoencoderKL.py --config ./configs/vae_xent.yaml



### 2. LDM (DDPM) training

#### Prepare training data
Prepare the data by exporting the latent space of the training data using the VAE model that was just trained. Output will be saved in H5 file format.
  
    >> export_latent.py [-h] --ver VER [--subset SUBSET] [--logs-dir LOGS_DIR]


H5 file contains minimum and maximum values of the latent space, which will be used to normalize the latent space during training. Mean and std of the latent space is saved in separate columns to be used for the sampling process during LDM training.
  
#### Train LDM
Train LDM for 50000 iterations
        
        ...


### 3. Inference

        ...






## Network overview
DIFF-3 is an unconditioned Latent Diffusion Model (LDM) consisting of two stages:

1. Variational Auto Encoder (VAE)
2. Denoising Diffusion Probabilistic Model (DDPM)

The code is modified based on the original implementation from [Latent Diffusion Models](https://github.com/CompVis/latent-diffusion) github, and adjusted to allow for 3D images+labels.

The image below shows the overview of the VAE network.
<p align="center">
    <img src="./images/fig_network.PNG">
</p>